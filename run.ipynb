{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048893d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from embeddings import *\n",
    "from preprocessing import *\n",
    "from models import *\n",
    "from fasttext_model import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189df5ea",
   "metadata": {},
   "source": [
    "## Load & Pre-process the training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = load_datasets(full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18482e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cleaned = tokenize_and_preprocess(df_train, stop_words = False, stemming = False, lemmatization = False, unslang_bool = True, remove_tags_bool = True, unelongate_bool = True, uncase_bool = True, smiley_to_word_bool = True)\n",
    "df_train_cleaned[\"label\"] = df_train[\"label\"]\n",
    "df_test_cleaned = tokenize_and_preprocess(df_test, stop_words = False, stemming = False, lemmatization = False, unslang_bool = True, remove_tags_bool = True, unelongate_bool = True, uncase_bool = True, smiley_to_word_bool = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cleaned[\"label\"] = df_train_cleaned[\"label\"].apply(lambda label: 1 if label == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7b925",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Glove embeddings \n",
    "df_train_vecs = tweet2vec(df_train_cleaned, \"glove\")\n",
    "df_test_vecs = tweet2vec(df_test_cleaned, \"glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899fdd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train/test (cross-validation ?)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_train_vecs[\"vectors\"], df_train_vecs[\"label\"], test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aca9be",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ad9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = train_test_model(\"LogisticRegression\", x_train.tolist(),y_train.tolist(),x_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3945ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,preds)  #0.748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faefffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = train_test_model(\"LogisticRegression\", df_train_vecs[\"vectors\"].tolist(),df_train_vecs[\"label\"].tolist(),df_test_vecs[\"vectors\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7976287",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = np.where(preds_submission < 0.5, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e1d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(preds_submission,\"submission_logreg_glove_.csv\") #0.729 0.729"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfe031",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3db189",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = train_test_model(\"SVM\", x_train.tolist(),y_train.tolist(),x_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6774b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,preds) #O.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ae811",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = train_test_model(\"SVM\", df_train_vecs[\"vectors\"].tolist(),df_train_vecs[\"label\"].tolist(),df_test_vecs[\"vectors\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = np.where(preds_submission < 0.5, -1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a343459",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f07808",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(preds_submission,\"submission_svm_glove.csv\") #0.729 0.730"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a2423b",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5d16a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds, loss, best_params = train_test_model(\"MLPClassifier\", x_train.tolist(),y_train.tolist(),x_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,preds) \n",
    "#solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1,max_iter=4000 \n",
    "#0.768 \n",
    "\n",
    "#solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(10, 4), random_state=1,max_iter=4000 \n",
    "#0.780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c9d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = train_test_model(\"NeuralNetwork\", df_train_vecs[\"vectors\"].tolist(),df_train_vecs[\"label\"].tolist(),df_test_vecs[\"vectors\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = np.where(preds_submission < 0.5, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34829dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(preds_submission,\"submission_nn_glove.csv\")\n",
    "#solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1,max_iter=4000 \n",
    "#0.730 0.734\n",
    "\n",
    "#solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(10, 4), random_state=1,max_iter=4000 \n",
    "#0.763 0.769"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3758991",
   "metadata": {},
   "source": [
    "# Fast-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d67e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fasttext = fasttext_label(df_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_train_fasttext[\"tweets\"], df_train_fasttext[\"label\"], test_size=0.4, random_state=0)\n",
    "train = pd.concat([x_train,y_train],axis=1)\n",
    "test = pd.concat([x_test,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = train_test_fasttext_model(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0680da",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "for label in y_test:\n",
    "    if label == \"__label__1\":\n",
    "        true_labels.append(1)\n",
    "    else:\n",
    "        true_labels.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21634e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(true_labels,preds) \n",
    "# 0.837 wiht no pre-process\n",
    "# 0.82 with no stop words, no stemming, no lemmatization\n",
    "# 0.67 with everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = train_test_fasttext_model(df_train_fasttext,df_test_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e31068",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(preds,\"submission_fasttext.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f28247",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Glove embeddings \n",
    "df_train_vecs = tweet2vec(df_train_cleaned, \"word2vec\")\n",
    "df_test_vecs = tweet2vec(df_test_cleaned, \"word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train/test (cross-validation ?)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_train_vecs[\"vectors\"], df_train_vecs[\"label\"], test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0629e224",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = train_test_model(\"LogisticRegression\", x_train.tolist(),y_train.tolist(),x_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc73258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,preds) #0.748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca1e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = train_test_model(\"LogisticRegression\", df_train_vecs[\"vectors\"].tolist(),df_train_vecs[\"label\"].tolist(),df_test_vecs[\"vectors\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f2d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_submission = np.where(preds_submission < 0.5, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a510bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(preds_submission,\"submission_logreg_word2vec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b27fd",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = train_test_model(\"SVM\", x_train.tolist(),y_train.tolist(),x_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,preds) #0.749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = train_test_model(\"SVM\", df_train_vecs[\"vectors\"].tolist(),df_train_vecs[\"label\"].tolist(),df_test_vecs[\"vectors\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = np.where(preds_submission < 0.5, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e474e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(preds_submission,\"submission_svm_word2vec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0390437",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d049b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = train_test_model(\"NeuralNetwork\", x_train.tolist(),y_train.tolist(),x_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d677f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95409a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = train_test_model(\"NeuralNetwork\", df_train_vecs[\"vectors\"].tolist(),df_train_vecs[\"label\"].tolist(),df_test_vecs[\"vectors\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3486c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_submission = np.where(preds_submission < 0.5, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e683131",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(preds_submission,\"submission_nn_word2vec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d285d2",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TBertModel, BertConfig, TFBertForSequenceClassification\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b71366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_inputs_bert(tweets,max_len):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for tweet in tweets:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            tweet,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        input_ids.append(encoded_dict[\"input_ids\"]) \n",
    "        attention_masks.append(encoded_dict[\"attention_mask\"])\n",
    "    # Return tensors    \n",
    "    input_ids = tf.convert_to_tensor(input_ids)\n",
    "    attention_masks = tf.convert_to_tensor(attention_masks)\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No pre-process\n",
    "x_train,x_test,y_train,y_test = train_test_split(df_train[\"tweets\"], df_train[\"label\"], test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = df_train.tweets.str.len().max() #Find longest tweet to define max length\n",
    "train_inp,train_masks = mask_inputs_bert(x_train,max_len)\n",
    "test_inp,test_masks = mask_inputs_bert(x_test,max_len)\n",
    "train_label = tf.convert_to_tensor(y_train)\n",
    "test_label = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3600e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c2fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-0.8)\n",
    "\n",
    "bert_model.compile(loss=loss,optimizer=optimizer,metrics=[metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751199df",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = bert_model.fit([train_inp,train_mask],train_label,batch_size=32,epochs=4,validation_data=([test_inp,test_mask],test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bert_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f13178e",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train[\"tweets\"]\n",
    "y = df_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f516733",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3765753",
   "metadata": {},
   "outputs": [],
   "source": [
    "token.fit_on_texts(x)\n",
    "seq = token.texts_to_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c937ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_seq = pad_sequences(seq,maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(token.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f229e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector = {}\n",
    "f = open('data/glove.twitter.27B.200d.txt',\"r\",encoding=\"utf8\")\n",
    "for line in tqdm(f):\n",
    "    value = line.split(' ')\n",
    "    word = value[0]\n",
    "    coef = np.array(value[1:],dtype = 'float32')\n",
    "    embedding_vector[word] = coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b01c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size,200))\n",
    "for word,i in tqdm(token.word_index.items()):\n",
    "    embedding_value = embedding_vector.get(word)\n",
    "    if embedding_value is not None:\n",
    "        embedding_matrix[i] = embedding_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test['tweets']\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "test_seq = pad_sequences(x_test,maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = train_test_rnn(\"RNN LSTM\", embedding_matrix, vocab_size, pad_seq, y, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affac23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds  = np.where(preds < 0.5, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92791996",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(preds,\"submission_rnn_lstm.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
